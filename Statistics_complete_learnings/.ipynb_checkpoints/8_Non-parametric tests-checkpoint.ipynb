{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Method\n",
    "\n",
    "All the test have some common features\n",
    "\n",
    "   * The form of frequency function of the parent population form which the samples have been drawn is assumed to be known, and\n",
    "   * They were concerned with testing statistical hypothesis about the parameters of this frequency function or estimating its parameter.\n",
    "\n",
    "But, `Non-parametric tests` is a test that does not depend on the particular form of the basic frequency function from which the samples are drawn. In other words, non-parametric test does not make any assumptions regarding the form of population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some assumptions associated are:\n",
    "\n",
    "   * Sample observations are independent\n",
    "   * The variable under study is continuous\n",
    "   * p.d.f is continuous\n",
    "\n",
    "These assumptions are much weaker than those associated with parametric test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Advantages and Disadvantages of non-parametric tests </h3>\n",
    "\n",
    "| Advantages                                                                                                                                                                | Disadvantages                                                                                                                                                                                                                                                                                                                                                                 |\n",
    "| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| Non-Parametric methods are readily comprehensible, very simple and easy to apply, and do not require complicated sample theory.                                           | Non,-Parametric tests can be used only if the measurements are nominal or ordinal. Even in that case, if a parametric test exists it is more powerful than the Non-Parametric test. In other words, if all the assumptions of a statistical model are satisfied by the data and if the measurements are of required strength, then the N.P test is wasteful of time and data. |\n",
    "| No assumptions are made about the form of the frequency function of the parent population from which sampling is done.                                                    | So far, no Non-Parametric methods exist for testing interactions in the \\`Analysis of variance\\` model unless special assumptions about the additivity of the model.                                                                                                                                                                                                          |\n",
    "| No parametric technique will apply to the data which are classification (measured in nominal scale) while Non-Parametric methods exist to deal with such data.            | Non-Parametric tests are designed to test statistical hypotheses only and not for estimating the parameters.                                                                                                                                                                                                                                                                   |\n",
    "| Science Socio-economic data are not, in general, normally distributed. Non-Parametric tests have found application in Psychometry, Sociology, and Educational Statistics. |                                                                                                                                                                                                                                                                                                                                                                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Man-Whitney U-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test is used for two-samples and most widely used to test as an alternative to the `t-test` we do not make the `t-test` assumptions about the parent population.\n",
    "\n",
    "Let $x_i(i=1,2, ..., n_1 )$ and $ y_j (j=1,2, ..., n_2)$ be independent ordered samples of size $n_1$ and $n_2$ from the populations with $ p.d.f \\: \\: f_1(.) $ and $ f_2(.) $ respectively. We want to test the null hypothesis \n",
    "$$ H_0: f_1(.) = f_2(.)  $$\n",
    "\n",
    "Test is based on the pattern of $x's$ and $y's$ in the combined ordered sample.\n",
    "\n",
    "LEt $T$ denote the sum of ranks of the $y's$ in the combined ordered sample. Then the statistic $U$ lis defined inn terms of $T$ as:\n",
    "\n",
    "$$ U = n_1 n_2 + \\frac {n_2 (n_2 + 1)} 2 - T $$\n",
    "\n",
    "if $T$ is significantly large of small the $H_0$ is rejected. By some experiments it has been established that under $H_0$, $U$ is asymptotically normally distributed as $N(\\mu, \\sigma^2)$, where\n",
    "\n",
    "$ \\mu = E(U) = \\frac {n_1n_2} 2 \\hspace{2em} and \\hspace{2em} \\sigma^2 = Var(U) = \\frac {n-1 n_2 (n_1 + n_2 + 1)} {12} $\n",
    "\n",
    "Hence, \n",
    "$$ Z = \\frac {U-\\mu} {\\sigma} \\sim N(0,1) $$\n",
    "\n",
    "This approximation is fairly good if both $n_1$ and $n_2$ are greater than 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the array of data\n",
    "X = np.array([10,16,8,20,14,12,9])\n",
    "Y = np.array([18,13,16,8,22,12,10,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the boxplots to visualize the distribution\n",
    "plt.boxplot(X, positions=[1])\n",
    "plt.boxplot(Y, positions=[2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the X and Y are almost similarly distributed and let's confirm that using Man-whitney test form SciPy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=22.5, pvalue=0.2805399647928408)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing man-whitney U test\n",
    "scipy.stats.mannwhitneyu(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, Based on the p_value we a accept the null hypothesis that the distribution are same.\n",
    "\n",
    "Now lets look at the another dataset where there is a actual difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare new set of data having different distribution\n",
    "X = np.array([1,2,4,3,5,4,5,4,7,6,7,9,10])\n",
    "Y = np.array([18,13,16,8,22,12,10,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot them to visualize\n",
    "plt.boxplot(X, positions=[1])\n",
    "plt.boxplot(Y, positions=[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=2.5, pvalue=0.0001877669631843385)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.mannwhitneyu(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, Based on the p_value we reject the Null hypotheses $(H_0)$ that distribution of the X and Y are same "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilcoxon Paired sample signed rank test\n",
    "\n",
    "Suppose $(x_i, y_i)$ be paired observations from a random sample of size n. $i=1,2, ..., n$. We want to test the hypothesis that $f_1(x) = f_2(y)$. Let $ d_i = x_i - y_i$, Some of $d_i$ are positive and some of $d_i$ are negative, the $|d_i| $ are ranked from 1 to n, then assign actual sign to all the $d_i$. Let $T^+$ is sum of positive rank and $T^-$ is the sum of negative rank. Let $T$ denote the smallest of $T^+$ and $T^-$.\n",
    "\n",
    "$ E(T) = \\frac {n(n+1)} 4$\n",
    "\n",
    "$ V(T) = \\frac { n (n+2) (2n+1)} {24} $\n",
    "\n",
    "$$ Z = \\frac {T-E(T)} {\\sqrt {V(T)}} \\sim N(0,1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let solve the problem manually then using python\n",
    "\n",
    "<h3> Example </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the two variables \n",
    "x = np.array([14,17,19,21,9,11,16,20,12,16,18,20])\n",
    "y = np.array([10,15,18,18,11,18,14,29,6,21,17,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 1, 3, 2, 7, 2, 9, 6, 5, 1, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the absolute difference d between x and y\n",
    "diff = x-y\n",
    "abs(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7. ,  4. ,  1.5,  6. ,  4. , 11. ,  4. , 12. , 10. ,  8.5,  1.5,\n",
       "        8.5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arrange them in order so that it will be easy to rank\n",
    "rank = scipy.stats.rankdata(abs(diff))\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now add the positive and negative difference in diff among them separately\n",
    "# and you can also count the number of positive and negative differences\n",
    "pos = 0\n",
    "neg = 0\n",
    "n_p = 0\n",
    "n_n = 0\n",
    "for i, j in zip(diff, rank):\n",
    "  if i > 0:\n",
    "    pos+= j\n",
    "    n_p+= 1\n",
    "  else:\n",
    "    neg += j\n",
    "    n_n+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42.5, 35.5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of positive ad negative ranks based on the sign of the difference\n",
    "pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of positive and negative differences\n",
    "n_p , n_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean of expectation of the T\n",
    "E_t = (len(x)*(len(x)+1))/4\n",
    "E_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance of T\n",
    "V_t = (len(x)*(len(x)+1)*(2*len(x)+1))/24\n",
    "V_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.27456258919345766"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the Z score for T-negative\n",
    "Z = (neg - E_t)/math.sqrt(V_t)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9599639845400545"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare it with Z-table value at 5% level of significance which is 1.96\n",
    "scipy.stats.norm.ppf(.05/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the p-value of standard normal distribution at z= -0.27 using `.sf ` method in `scipy.stats` normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7836523115344085"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply it by 2 because it is two tailed test and it gives value at alpha/2\n",
    "scipy.stats.norm.sf(abs(Z))*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the p-value we can accept the null hypothesis that the distribution of both X and Y are same\n",
    "\n",
    "Now we can see that using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=35.5, pvalue=0.7831638185341272)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.wilcoxon(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the p_value is same as calculated and the test statistic is the value of `T` having small value amount T-positive and T-negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: These results will are calculated using `python 3.7.13` and `SciPy version 1.4.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KrusKall Wallis Test\n",
    "\n",
    "Let us suppose that there are $k$ populations. Sample of size $ n_1, n_2, ..., n_k $ is drawn from first, second, third, ..., $k^{th}$ population such that $ n_1 + n_2 + ...+ n_k = N$. To test the hypothesis that samples have been drawn from the populations having same distribution.\n",
    "\n",
    "This test is similar to parametric test of one-way anova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the observations and arrange them in increasing or decreasing order. Rank the observations form $1$ t $N$. FPr tied ranks give common rank which is the mean of rank of tied observations. After given the rank to all observations, separate teh the rank gor each group. Find the total of ranks for each group. Let $R_i$ be the sum of rank of $i_{th}$ group\n",
    "\n",
    "To test the hypothesis\n",
    "\n",
    "$ H_0:$ All the groups have same distribution.\n",
    "$ H_1:$ Atleast two of the population have different distribution.\n",
    "\n",
    "Test statistic \n",
    "\n",
    "$$ H = \\frac {12} {N(N+1)} \\sum _{i=1} ^{k} \\frac {R_1^2} { n_1} -3(N+1) $$\n",
    "\n",
    "Compare the $H$ with $\\chi^2$ table with $k-1$ degree of freedom with 5% level of significance. If $H<\\chi^2$, $H_0$ is not rejected $i.e.;$ all the group are equally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Example </h3>\n",
    "\n",
    "Three samples of size 10, 8, 7 were selected and following is the observation. Test that distribution os same by using Kruskall wallis Test.\n",
    "\n",
    "| A  | B  | C  |\n",
    "| -- | -- | -- |\n",
    "| 14 | 10 | 29 |\n",
    "| 17 | 15 | 6  |\n",
    "| 19 | 18 | 21 |\n",
    "| 21 | 18 | 17 |\n",
    "| 9  | 11 | 15 |\n",
    "| 11 | 18 | 18 |\n",
    "| 16 | 14 | 20 |\n",
    "| 20 | 26 |    |\n",
    "| 12 |    |    |\n",
    "| 16 |    |    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Solution </h3>\n",
    "\n",
    "Arrange them in ascending order and rank them.\n",
    "\n",
    "Let's do it using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare all of them as individual array\n",
    "x = np.array([14, 17, 19, 21, 9, 11, 16, 20, 12, 16])\n",
    "y = np.array([10, 15, 18, 18, 11, 18, 14, 26])\n",
    "z = np.array([29, 6, 21, 17, 15, 18, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 17, 19, 21,  9, 11, 16, 20, 12, 16, 10, 15, 18, 18, 11, 18, 14,\n",
       "       26, 29,  6, 21, 17, 15, 18, 20])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # combine all the arrays\n",
    " combined = np.concatenate([x,y,z])\n",
    " combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.5, 13.5, 19. , 22.5,  2. ,  4.5, 11.5, 20.5,  6. , 11.5,  3. ,\n",
       "        9.5, 16.5, 16.5,  4.5, 16.5,  7.5, 24. , 25. ,  1. , 22.5, 13.5,\n",
       "        9.5, 16.5, 20.5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rank the data and take care of tied ranks\n",
    "rank = scipy.stats.rankdata(combined)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of all the ranks individually\n",
    "stop_idx = len(x)\n",
    "stop_idy = stop_idx+len(y)\n",
    "stop_idz = stop_idy+len(z)\n",
    "\n",
    "R_1 = rank[:stop_idx].sum()\n",
    "R_2 = rank[stop_idx:stop_idy].sum()\n",
    "R_3 = rank[stop_idy:stop_idz].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118.5, 98.0, 108.5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_1, R_2, R_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\sum \\frac {R_1^2} {n_1} = 1404.23 + 1200.50 + 1681.75 = 4286.48 $$\n",
    "\n",
    "$$ H = \\frac {12} {25(25+1)} 4286.48 - 3(25+1) = 1.13$$\n",
    "\n",
    "for chi-square table [click here](https://people.richland.edu/james/lecture/m170/tbl-chi.html)\n",
    "\n",
    "Check $\\chi^2$ value at 2 $d.f$ and 5% $ \\alpha$ which is 5.99. Since H is less than 5.99. $H_0$ is not rejected $i.e.$ all samples have been drawn from the population having same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4286.475"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solving using python\n",
    "\n",
    "rank_sum = (R_1**2)/len(x) + (R_2**2)/len(y) + (R_3**2)/len(z)\n",
    "\n",
    "rank_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1349230769230871"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = ((12 / (len(combined)* (len(combined)+1))) * rank_sum) - (3*(len(combined)+1))\n",
    "\n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare it with table value 5.99\n",
    "\n",
    "Now we can solve it using the python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=1.142392566782821, pvalue=0.5648493145085038)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.kruskal(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, Based on p-value we can accept the null hypothesis that the samples are drawn from the population having same distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friedman's Test\n",
    "\n",
    "The test is similar to parametric of two-way anova. It is a ideal statistic to use for a repeated measures.\n",
    "\n",
    "Suppose there ar $v$ treatments and each treatment is repeated $r$ number of times. The observations for each treatment is ranked from $1$ to $v$ in each block separately find the sum of rank for each treatment and let $R_i$ be the sum of rank for $t^{th}$ treatment. To test the hypothesis that all treatments are equally effective, test statistic is,\n",
    "\n",
    "$$ F = \\frac {12} {rv(v+1)} \\sum _{i=1} ^{v} R_i^2 - 3r(v+1) $$\n",
    "\n",
    "compare $F_{calculated}$ with $\\chi^2$ table with $v-1$ degree of freedom at 5% level of significance. If $F < \\chi ^2 $ table value. $H_0$ is not rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Example </h3>\n",
    "\n",
    "Eight treatment were replicated 4 times. Test that distribution of 8 treatments is same using Friedman's test.\n",
    "\n",
    "| Treatment | $R_1$ | $R_2$ | $R_3$ | $R_4$ |\n",
    "| --------- | ------ | ------ | ------ | ------ |\n",
    "| A         | 11     | 13     | 12     | 15     |\n",
    "| B         | 13     | 15     | 16     | 18     |\n",
    "| C         | 14     | 18     | 17     | 17     |\n",
    "| D         | 17     | 18     | 17     | 19     |\n",
    "| E         | 9      | 11     | 10     | 22     |\n",
    "| F         | 11     | 13     | 15     | 21     |\n",
    "| G         | 16     | 14     | 17     | 24     |\n",
    "| H         | 20     | 22     | 24     | 23     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the variable for all the replications\n",
    "x1 = np.array([11,13,14,17,9,11,16,20])\n",
    "x2 = np.array([13,15,18,18,11,13,14,22])\n",
    "x3 = np.array([12,16,17,17,10,15,17,24])\n",
    "x4 = np.array([15,18,17,19,22,21,24,23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FriedmanchisquareResult(statistic=15.499999999999982, pvalue=0.0014355858803625078)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.friedmanchisquare(x1,x2,x3,x4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From p-value we can reject the null hypothesis and the distribution of treatments are different."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a27f6fbcd67765101d4e4574480442f506810e4746b454d2c175101bdaf3f6b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
